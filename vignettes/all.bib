
@article{quan_coding_2005,
  title = {Coding {{Algorithms}} for {{Defining Comorbidities}} in {{ICD}}-9-{{CM}} and {{ICD}}-10 {{Administrative Data}}},
  volume = {43},
  copyright = {Copyright \textcopyright{} 2005 Lippincott Williams \& Wilkins},
  issn = {0025-7079},
  abstract = {Objectives: Implementation of the International Statistical Classification of Disease and Related Health Problems, 10th Revision (ICD-10) coding system presents challenges for using administrative data. Recognizing this, we conducted a multistep process to develop ICD-10 coding algorithms to define Charlson and Elixhauser comorbidities in administrative data and assess the performance of the resulting algorithms. Methods: ICD-10 coding algorithms were developed by "translation" of the ICD-9-CM codes constituting Deyo's (for Charlson comorbidities) and Elixhauser's coding algorithms and by physicians' assessment of the face-validity of selected ICD-10 codes. The process of carefully developing ICD-10 algorithms also produced modified and enhanced ICD-9-CM coding algorithms for the Charlson and Elixhauser comorbidities. We then used data on in-patients aged 18 years and older in ICD-9-CM and ICD-10 administrative hospital discharge data from a Canadian health region to assess the comorbidity frequencies and mortality prediction achieved by the original ICD-9-CM algorithms, the enhanced ICD-9-CM algorithms, and the new ICD-10 coding algorithms. Results: Among 56,585 patients in the ICD-9-CM data and 58,805 patients in the ICD-10 data, frequencies of the 17 Charlson comorbidities and the 30 Elixhauser comorbidities remained generally similar across algorithms. The new ICD-10 and enhanced ICD-9-CM coding algorithms either matched or outperformed the original Deyo and Elixhauser ICD-9-CM coding algorithms in predicting in-hospital mortality. The C-statistic was 0.842 for Deyo's ICD-9-CM coding algorithm, 0.860 for the ICD-10 coding algorithm, and 0.859 for the enhanced ICD-9-CM coding algorithm, 0.868 for the original Elixhauser ICD-9-CM coding algorithm, 0.870 for the ICD-10 coding algorithm and 0.878 for the enhanced ICD-9-CM coding algorithm. Conclusions: These newly developed ICD-10 and ICD-9-CM comorbidity coding algorithms produce similar estimates of comorbidity prevalence in administrative data, and may outperform existing ICD-9-CM coding algorithms.},
  number = {11},
  journal = {Medical Care},
  author = {Quan, Hude and Sundararajan, Vijaya and Halfon, Patricia and Fong, Andrew and Burnand, Bernard and Luthi, Jean-Christophe and Saunders, L. Duncan and Beck, Cynthia A. and Feasby, Thomas E. and Ghali, William A.},
  month = nov,
  year = {2005},
  pages = {1130-1139}
}

@article{diamond_genetic_2012,
  title = {Genetic {{Matching}} for {{Estimating Causal Effects}}: {{A General Multivariate Matching Method}} for {{Achieving Balance}} in {{Observational Studies}}},
  issn = {0034-6535},
  shorttitle = {Genetic {{Matching}} for {{Estimating Causal Effects}}},
  doi = {10.1162/REST_a_00318},
  abstract = {This paper presents genetic matching, a method of multivariate matching that uses an evolutionary search algorithm to determine the weight each covariate is given. Both propensity score matching and matching based on Mahalanobis distance are limiting cases of this method. The algorithm makes transparent certain issues that all matching methods must confront. We present simulation studies that show that the algorithm improves covariate balance and that it may reduce bias if the selection on observables assumption holds. We then present a reanalysis of a number of data sets in the LaLonde (1986) controversy.},
  journal = {Review of Economics and Statistics},
  author = {Diamond, Alexis and Sekhon, Jasjeet S.},
  month = oct,
  year = {2012}
}

@article{simpao_big_2015,
  title = {Big Data and Visual Analytics in Anaesthesia and Health Care},
  issn = {0007-0912, 1471-6771},
  doi = {10.1093/bja/aeu552},
  abstract = {Advances in computer technology, patient monitoring systems, and electronic health record systems have enabled rapid accumulation of patient data in electronic form (i.e. big data). Organizations such as the Anesthesia Quality Institute and Multicenter Perioperative Outcomes Group have spearheaded large-scale efforts to collect anaesthesia big data for outcomes research and quality improvement. Analytics\textemdash{}the systematic use of data combined with quantitative and qualitative analysis to make decisions\textemdash{}can be applied to big data for quality and performance improvements, such as predictive risk assessment, clinical decision support, and resource management. Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces, and it can facilitate performance of cognitive activities involving big data. Ongoing integration of big data and analytics within anaesthesia and health care will increase demand for anaesthesia professionals who are well versed in both the medical and the information sciences.},
  language = {en},
  journal = {British Journal of Anaesthesia},
  author = {Simpao, A. F. and Ahumada, L. M. and Rehman, M. A.},
  month = jan,
  year = {2015},
  keywords = {decision support systems; clinical,electronic health records,integrated advanced information management systems,medical informatics},
  pages = {aeu552},
  pmid = {25627395}
}

@article{elixhauser_comorbidity_1998,
  title = {Comorbidity {{Measures}} for {{Use}} with {{Administrative Data}}},
  volume = {36},
  issn = {0025-7079},
  abstract = {Objectives. This study attempts to develop a comprehensive set of comorbidity measures for use with large administrative inpatient datasets., Methods. The study involved clinical and empirical review of comorbidity measures, development of a framework that attempts to segregate comorbidities from other aspects of the patient's condition, development of a comorbidity algorithm, and testing on heterogeneous and homogeneous patient groups. Data were drawn from all adult, nonmaternal inpatients from 438 acute care hospitals in California in 1992 (n = 1,779,167). Outcome measures were those commonly available in administrative data: length of stay, hospital charges, and in-hospital death., Results. A comprehensive set of 30 comorbidity measures was developed. The comorbidities were associated with substantial increases in length of stay, hospital charges, and mortality both for heterogeneous and homogeneous disease groups. Several comorbidities are described that are important predictors of outcomes, yet commonly are not measured. These include mental disorders, drug and alcohol abuse, obesity, coagulopathy, weight loss, and fluid and electrolyte disorders., Conclusions. The comorbidities had independent effects on outcomes and probably should not be simplified as an index because they affect outcomes differently among different patient groups. The present method addresses some of the limitations of previous measures. It is based on a comprehensive approach to identifying comorbidities and separates them from the primary reason for hospitalization, resulting in an expanded set of comorbidities that easily is applied without further refinement to administrative data for a wide range of diseases., (C) Lippincott-Raven Publishers},
  number = {1},
  journal = {Medical Care January 1998},
  author = {Elixhauser, Anne and Steiner, Claudia and Harris, D. Robert and Coffey, Rosanna M.},
  year = {1998},
  keywords = {Clinical Medicine; Behavioral \& Social Sciences},
  pages = {8-27}
}

@article{quan_updating_2011,
  title = {Updating and {{Validating}} the {{Charlson Comorbidity Index}} and {{Score}} for {{Risk Adjustment}} in {{Hospital Discharge Abstracts Using Data From}} 6 {{Countries}}},
  volume = {173},
  issn = {0002-9262, 1476-6256},
  doi = {10.1093/aje/kwq433},
  abstract = {With advances in the effectiveness of treatment and disease management, the contribution of chronic comorbid diseases (comorbidities) found within the Charlson comorbidity index to mortality is likely to have changed since development of the index in 1984. The authors reevaluated the Charlson index and reassigned weights to each condition by identifying and following patients to observe mortality within 1 year after hospital discharge. They applied the updated index and weights to hospital discharge data from 6 countries and tested for their ability to predict in-hospital mortality. Compared with the original Charlson weights, weights generated from the Calgary, Alberta, Canada, data (2004) were 0 for 5 comorbidities, decreased for 3 comorbidities, increased for 4 comorbidities, and did not change for 5 comorbidities. The C statistics for discriminating in-hospital mortality between the new score generated from the 12 comorbidities and the Charlson score were 0.825 (new) and 0.808 (old), respectively, in Australian data (2008), 0.828 and 0.825 in Canadian data (2008), 0.878 and 0.882 in French data (2004), 0.727 and 0.723 in Japanese data (2008), 0.831 and 0.836 in New Zealand data (2008), and 0.869 and 0.876 in Swiss data (2008). The updated index of 12 comorbidities showed good-to-excellent discrimination in predicting in-hospital mortality in data from 6 countries and may be more appropriate for use with more recent administrative data.},
  language = {en},
  number = {6},
  journal = {American Journal of Epidemiology},
  author = {Quan, Hude and Li, Bing and Couris, Chantal M. and Fushimi, Kiyohide and Graham, Patrick and Hider, Phil and Januel, Jean-Marie and Sundararajan, Vijaya},
  month = mar,
  year = {2011},
  keywords = {Comorbidity,International Classification of Diseases,mortality,Quality of Health Care,risk adjustment},
  pages = {676-682},
  pmid = {21330339}
}

@article{charlson_new_1987,
  title = {A New Method of Classifying Prognostic Comorbidity in Longitudinal Studies: {{Development}} and Validation},
  volume = {40},
  issn = {0021-9681},
  shorttitle = {A New Method of Classifying Prognostic Comorbidity in Longitudinal Studies},
  doi = {10.1016/0021-9681(87)90171-8},
  abstract = {The objective of this study was to develop a prospectively applicable method for classifying comorbid conditions which might alter the risk of mortality for use in longitudinal studies. A weighted index that takes into account the number and the seriousness of comorbid disease was developed in a cohort of 559 medical patients. The 1-yr mortality rates for the different scores were: ``0'', 12\% (181); ``1\textendash{}2'', 26\% (225); ``3\textendash{}4'', 52\% (71); and ``$\geqslant$ 5'', 85\% (82). The index was tested for its ability to predict risk of death from comorbid disease in the second cohort of 685 patients during a 10-yr follow-up. The percent of patients who died of comorbid disease for the different scores were: ``0'', 8\% (588); ``1'', 25\% (54); ``2'', 48\% (25); `` $\geqslant$ 3'', 59\% (18). With each increased level of the comorbidity index, there were stepwise increases in the cumulative mortality attributable to comorbid disease (log rank $\chi$2 = 165; p \&lt; 0.0001). In this longer follow-up, age was also a predictor of mortality (p \&lt; 0.001). The new index performed similarly to a previous system devised by Kaplan and Feinstein. The method of classifying comorbidity provides a simple, readily applicable and valid method of estimating risk of death from comorbid disease for use in longitudinal studies. Further work in larger populations is still required to refine the approach because the number of patients with any given condition in this study was relatively small.},
  number = {5},
  journal = {Journal of Chronic Diseases},
  author = {Charlson, Mary E. and Pompei, Peter and Ales, Kathy L. and MacKenzie, C. Ronald},
  year = {1987},
  pages = {373-383}
}

@article{Eddelbuettel_RcppSeamlessIntegration_2011,
  title = {Rcpp: {{Seamless R}} and {{C}}++ {{Integration}} | {{Eddelbuettel}} | {{Journal}} of {{Statistical Software}}},
  volume = {40},
  shorttitle = {Rcpp},
  doi = {10.18637/jss.v040.i08},
  language = {en-US},
  number = {8},
  journal = {Journal of Statistical Software},
  author = {Eddelbuettel, Dirk and Francois, Romain},
  year = {2011}
}

@article{Eddelbeuttel_FastElegantNumerical_2013,
  title = {Fast and {{Elegant Numerical Linear Algebra Using}} the {{RcppEigen Package}} | {{Bates}} | {{Journal}} of {{Statistical Software}}},
  volume = {52},
  doi = {10.18637/jss.v052.i05},
  language = {en-US},
  number = {5},
  journal = {Journal of Statistical Software},
  author = {Eddelbeuttel, Dirk and Bates, Douglas},
  year = {2013}
}

@misc{Guennebaud_Eigen3_2017,
  title = {Eigen3},
  abstract = {Eigen is versatile.
        It supports all matrix sizes, from small fixed-size matrices to arbitrarily large dense matrices, and even sparse matrices.
        It supports all standard numeric types, including std::complex, integers, and is easily extensible to custom numeric types.
        It supports various matrix decompositions and geometry features.
        Its ecosystem of unsupported modules provides many specialized features such as non-linear optimization, matrix functions, a polynomial solver, FFT, and much more.
    Eigen is fast.
        Expression templates allow to intelligently remove temporaries and enable lazy evaluation, when that is appropriate.
        Explicit vectorization is performed for SSE 2/3/4, AVX, FMA, AVX512, ARM NEON (32-bit and 64-bit), PowerPC AltiVec/VSX (32-bit and 64-bit) instruction sets, and now S390x SIMD (ZVector) with graceful fallback to non-vectorized code.
        Fixed-size matrices are fully optimized: dynamic memory allocation is avoided, and the loops are unrolled when that makes sense.
        For large matrices, special attention is paid to cache-friendliness.
    Eigen is reliable.
        Algorithms are carefully selected for reliability. Reliability trade-offs are clearly documented and extremely safe decompositions are available.
        Eigen is thoroughly tested through its own test suite (over 500 executables), the standard BLAS test suite, and parts of the LAPACK test suite.
    Eigen is elegant.
        The API is extremely clean and expressive while feeling natural to C++ programmers, thanks to expression templates.
        Implementing an algorithm on top of Eigen feels like just copying pseudocode.
    Eigen has good compiler support as we run our test suite against many compilers to guarantee reliability and work around any compiler bugs. Eigen also is standard C++98 and maintains very reasonable compilation times.},
  howpublished = {https://eigen.tuxfamily.org/index.php?title=Main\_Page},
  author = {Guennebaud, G and Jacob, B and {et al}},
  year = {2017}
}

@article{vanWalraven_modification_2009,
  title = {A Modification of the {{Elixhauser}} Comorbidity Measures into a Point System for Hospital Death Using Administrative Data},
  volume = {47},
  issn = {1537-1948},
  doi = {10.1097/MLR.0b013e31819432e5},
  abstract = {BACKGROUND: Comorbidity measures are necessary to describe patient populations and adjust for confounding. In direct comparisons, studies have found the Elixhauser comorbidity system to be statistically slightly superior to the Charlson comorbidity system at adjusting for comorbidity. However, the Elixhauser classification system requires 30 binary variables, making its use for reporting and analysis of comorbidity cumbersome.
OBJECTIVE: Modify the Elixhauser classification system into a single numeric score for administrative data.
METHODS: For all hospitalizations at the Ottawa Hospital, Canada, between 1996 and 2008, we determined if International Classification of Disease codes for chronic diagnoses were in any of the 30 Elixhauser comorbidity groups. We then used backward stepwise multivariate logistic regression to determine the independent association of each comorbidity group with death in hospital. Regression coefficients were modified into a scoring system that reflected the strength of each comorbidity group's independent association with hospital death.
RESULTS: Hospitalizations that were included were 345,795 (derivation: 228,565; validation 117,230). Twenty-one of the 30 groups were independently associated with hospital mortality. The resulting comorbidity score had an equivalent discrimination in the derivation and validation groups (overall c-statistic 0.763, 95\% CI: 0.759-0.766). This was similar to models having all Elixhauser groups (0.760, 95\% CI: 0.756-0.764) or significant groups only (0.759, 95\% CI: 0.754-0.762), but significantly exceeded discrimination when comorbidity was expressed using the Charlson score (0.745, 95\% CI: 0.742-0.749).
CONCLUSION: When analyzing administrative data, the Elixhauser comorbidity system can be condensed to a single numeric score that summarizes disease burden and is adequately discriminative for death in hospital.},
  language = {eng},
  number = {6},
  journal = {Medical Care},
  author = {{van Walraven}, Carl and Austin, Peter C. and Jennings, Alison and Quan, Hude and Forster, Alan J.},
  month = jun,
  year = {2009},
  keywords = {Cohort Studies,Comorbidity,Health Services Research,Hospital Administration,Hospital Mortality,Hospitals; Teaching,Humans,International Classification of Diseases,Models; Statistical,Risk Adjustment},
  pages = {626-633},
  pmid = {19433995}
}

@misc{AgencyforHealthcareResearchandQuality_ElixhauserComorbiditySoftware_2018,
  type = {Text},
  title = {Elixhauser {{Comorbidity Software}} for {{ICD}}-10-{{CM Healthcare Cost}} and {{Utilization Project}} ({{HCUP}})},
  howpublished = {https://www.hcup-us.ahrq.gov/toolssoftware/comorbidityicd10/comorbidity\_icd10.jsp},
  author = {{Agency for Healthcare Research and Quality}},
  month = mar,
  year = {2018},
  note = {Agency for Healthcare Research and Quality, Rockville, MD}
}

@inproceedings{Jarvi_Algorithm_2006,
  address = {New York, NY, USA},
  series = {PLDI '06},
  title = {Algorithm {{Specialization}} in {{Generic Programming}}: {{Challenges}} of {{Constrained Generics}} in {{C}}++},
  isbn = {978-1-59593-320-1},
  shorttitle = {Algorithm {{Specialization}} in {{Generic Programming}}},
  doi = {10.1145/1133981.1134014},
  abstract = {Generic programming has recently emerged as a paradigm for developing highly reusable software libraries, most notably in C++. We have designed and implemented a constrained generics extension for C++ to support modular type checking of generic algorithms and to address other issues associated with unconstrained generics. To be as broadly applicable as possible, generic algorithms are defined with minimal requirements on their inputs. At the same time, to achieve a high degree of efficiency, generic algorithms may have multiple implementations that exploit features of specific classes of inputs. This process of algorithm specialization relies on non-local type information and conflicts directly with the local nature of modular type checking. In this paper, we review the design and implementation of our extensions for generic programming in C++, describe the issues of algorithm specialization and modular type checking in detail, and discuss the important design tradeoffs in trying to accomplish both.We present the particular design that we chose for our implementation, with the goal of hitting the sweet spot in this interesting design space.},
  booktitle = {Proceedings of the 27th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  publisher = {{ACM}},
  author = {J{\"a}rvi, Jaakko and Gregor, Douglas and Willcock, Jeremiah and Lumsdaine, Andrew and Siek, Jeremy},
  year = {2006},
  keywords = {concepts,constrained generics,generic programming,parametric polymorphism,specialization},
  pages = {272--282}
}

@misc{AgencyforHealthcareResearchandQuality_ClinicalClassificationsSoftware_2012,
  type = {Text},
  title = {Clinical {{Classifications Software}} for {{ICD}}-10 {{Data}}},
  language = {en-us},
  howpublished = {http://www.ahrq.gov/research/data/hcup/icd10usrgd.html},
  author = {{Agency for Healthcare Research and Quality}},
  year = {2012},
  note = {Agency for Healthcare Research and Quality, Rockville, MD, USA}
}

@article{Evans_EvaluationCMSHCCRisk_2011,
  title = {Evaluation of the {{CMS}}-{{HCC Risk Adjustment Model}}},
  language = {en},
  author = {Evans, Melissa A.},
  month = mar,
  year = {2011},
  pages = {127}
}

@article{Pope_RiskadjustmentMedicare_2004,
  title = {Risk Adjustment of {{Medicare}} Capitation Payments Using the {{CMS}}-{{HCC}} Model., {{Risk Adjustment}} of {{Medicare Capitation Payments Using}} the {{CMS}}-{{HCC Model}}},
  volume = {25, 25},
  issn = {0195-8631},
  abstract = {FULL TEXT Abstract: This article describes the CMS hierarchical condition categories (HCC) model implemented in 2004 to adjust Medicare capitation payments to...},
  language = {eng},
  number = {4, 4},
  journal = {Health care financing review, Health Care Financing Review},
  author = {Pope, G. C. and Kautter, J. and Ellis, R. P. and Ash, A. S. and Ayanian, J. Z. and Lezzoni, L. I. and Ingber, M. J. and Levy, J. M. and Robst, J.},
  year = {2004},
  pages = {119, 119-141},
  pmid = {15493448}
}

@misc{VermontDepartmentofHealth_VermontHospitalDischarge_2016,
  title = {Vermont {{Hospital Discharge Data}}},
  abstract = {The Vermont Uniform Hospital Discharge Data Set consists of inpatient discharge data, outpatient procedures and services data, and emergency department data. Each data set includes:},
  language = {en},
  howpublished = {http://www.healthvermont.gov/health-statistics-vital-records/health-care-systems-reporting/hospital-discharge-data},
  journal = {Vermont Department of Health},
  author = {{Vermont Department of Health}},
  month = jul,
  year = {2016},
  note = {Online; accessed 5-May-2018}
}


  @Manual{medicalriskpkg,
    title = {medicalrisk: Medical Risk and Comorbidity Tools for ICD-9-CM Data},
    author = {Patrick McCormick and Thomas Joseph},
    year = {2016},
    note = {R package version 12},
    url = {https://CRAN.R-project.org/package=medicalrisk}
  }

  @Article{comorbiditypkg,
    author = {Alessandro Gasparini},
    title = {Comorbidity: An R Package for Computing Comorbidity Scores},
    journal = {Journal of Open Source Software},
    year = {2018},
    volume = {3},
    issue = {23},
    pages = {648},
    doi = {10.21105/joss.00648},
    url = {https://doi.org/10.21105/joss.00648},
  }

  @Manual{R_2018,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2018},
    url = {https://www.R-project.org/},
  }

  @MISC{eigenweb,
    author = {Gael Guennebaud and Benoit Jacob and others},
    title = {Eigen v3, A C++ Template Library for Linear Algebra: Matrices, Vectors, Numerical Solvers, and Related Algorithms.},
    version = {3},
    howpublished = {http://eigen.tuxfamily.org},
    year = {2010},
    note = {Online; accessed 5-May-2018}
  }
@misc{gplv3,
  title        = {GNU General Public License},
  author       = "{Free Software Foundation}",
  version      = {3},
  shorthand    = {GPL},
  organization = {Free Software Foundation},
  url          = {http://www.gnu.org/licenses/gpl.html},
  pagination   = {section},
  language     = {english},
  date         = {2007-06-29},
  year         = {2007}
  }
